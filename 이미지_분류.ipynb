{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST DATA SET"
      ],
      "metadata": {
        "id": "FluG7PSH6yUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 주로 CNN에서 좋은 성능을 보임\n",
        "- 그 이유는 이미지 데이터의 공간적 구조를 효과적으로 학습할 수 있기 때문\n",
        "- MLP: Fully Connected Layer를 사용해 입력 이미지를 1D 벡터로 변환해 학습함\n",
        "- 하지만 CNN은 합성곱 연산(Convolution)을 사용하여 지역적 특징(Local Patterns)을 학습하고, 풀링(Pooling) 연산을 통해 불필요한 정보를 제거하면서도 중요한 특징을 유지할 수 있음\n",
        "- Ex. MNIST 숫자 '3'의 픽셀 위치가 조금 이동했다면\n",
        "  - MLP: 모든 픽셀을 일렬로 펼쳐 학습하므로, '3'의 위치가 조금만 달라져도 같은 숫자로 인식하지 못할 수 있음\n",
        "  - CNN: 합성곱 필터가 특정 패턴을 학습하므로, '3'의 위치가 달라져도 같은 숫자로 인식 가능"
      ],
      "metadata": {
        "id": "fpui9Q60610F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN의 핵심 메커니즘"
      ],
      "metadata": {
        "id": "mYWZDCyk8yl_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) 합성곱(Convolution) 연산\n",
        "- CNN의 핵심은 작은 필터(커널)을 사용하여 지역적인 특징을 학습하는 것\n",
        "- 엣지(Edge), 코너(Corner), 선(Line) 등을 감지할 수 있음\n",
        "- CNN은 계층을 쌓으면서 더 복잡한 특징을 학습함\n",
        "  - 초기 계층 -> 단순한 패턴(엣지, 코너)\n",
        "  - 중간 계층 -> 숫자의 일부 패턴 학습\n",
        "  - 최종 계층 -> 숫자 전체 형태 학습\n",
        "\n",
        "2) 풀링(Pooling) 연산\n",
        "- 최대 풀링(Max Pooling) 또는 평균 풀링(Average Pooling)을 통해 불필요한 정보 제거 & 중요한 특징 유지\n",
        "- 공간 정보를 유지하면서도 모델이 더 일반화될 수 있도록 돕는다\n",
        "- 위치 변화에 대한 불변성(Translation Invariance)을 증가시킨다\n",
        "\n",
        "3) 가중치 공유(Weight Sharing)\n",
        "- 일반적인 MLP에는 모든 뉴런이 고유한 가중치(Weight)를 학습하지만, CNN에서는 필터가 모든 영역에서 공유된다.\n",
        "- 이는 파라미터 수를 대폭 감소시키고 연산 효율을 높이며 과적합(Overfitting)도 방지할 수 있다.\n",
        "\n",
        "**즉, CNN은 이미지의 공간 구조를 그대로 학습할 수 있어 성능이 우수함**"
      ],
      "metadata": {
        "id": "OMr-0-rb83LF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 주요 연구 내용"
      ],
      "metadata": {
        "id": "hjtFghZP-Dzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) LeCun et al. (1998) - “Gradient-Based Learning Applied to Document Recognition”\n",
        "- Yann LeCun이 제안한 LeNet-5 모델 소개하는 논문\n",
        "- CNN이 MNIST에서 뛰어난 성능 보임\n",
        "- 합성곱 계층(Convolutional Layer)과 풀링 계층(Pooling Layer)을 조합하여 특징 효과적으로 추출\n",
        "- 기존 MLP와 비교해 더 높은 정확도와 일반화 성능 달성\n",
        "\n",
        "(2) Krizhevsky et al. (2012) - “ImageNet Classification with Deep Convolutional Neural Networks” (AlexNet)\n",
        "- AlexNet을 제안하며, CNN이 대규모 이미지 분류에서 뛰어난 성능을 보임\n",
        "- 더 복잡한 이미지에서도 CNN이 효과적\n",
        "- ReLU 활성화 함수 적용해 비선형 표현력 강화\n",
        "- 드롭아웃(Dropout) 기법 사용해 과적합 방지\n",
        "- 합성곱 연산 깊이 쌓아 학습 성능 극대화\n",
        "\n",
        "(3) He et al. (2016) - “Deep Residual Learning for Image Recognition” (ResNet)\n",
        "- Residual Learning(잔차 학습) 기법을 도입하여 깊은 신경망의 학습 문제를 해결\n",
        "- MNIST 같은 간단한 데이터뿐만 아니라, 복잡한 이미지 데이터에서도 CNN이 강력함을 입증\n",
        "- ResNet 블록을 사용하면 매우 깊은 CNN 네트워크도 효과적으로 학습 가능\n",
        "- 일반적인 CNN 모델(LeNet-5)보다 더 높은 정확도를 달성 가능\n",
        "- MNIST에서도 ResNet 적용하면 정확도 99.5% 이상으로 향상됨"
      ],
      "metadata": {
        "id": "fa2OJrAT-HeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "따라서 본 코드에서는\n",
        "- Residual Block을 사용\n",
        "- Batch Normalization & Dropout 추가\n",
        "- ReLU 활성화 함수 적용\n",
        "- Adam 옵티마이저 사용\n",
        "- Data Augmentation을 활용하고자 함"
      ],
      "metadata": {
        "id": "37f8m6ivAFtl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library Load"
      ],
      "metadata": {
        "id": "OOlQmGwq5Jmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "88iHZrH_AdlI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing & Data Augmentation"
      ],
      "metadata": {
        "id": "TdHW_NveIv0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이미지 회전 -> 모델이 다양한 방향의 숫자를 인식할 수 있도록\n",
        "- 랜덤한 기하학적 변환 -> 모델이 다양한 필기 스타일을 인식할 수 있도록\n",
        "- ToTensor -> 흑백 이미지(1채널), 각 픽셀 값[0, 255] 범위 갖는데, 이를 [0, 1]로 변환\n",
        "- Normalize -> 신경망 학습이 더 빠르고 안정적으로 이뤄지기 위함과 Gradient Vanishing 문제 방지(값이 너무 크거나 작으면 학습 어려움)"
      ],
      "metadata": {
        "id": "7Yc1Dbm7JAqR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1aMNPwDd45bi"
      },
      "outputs": [],
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomRotation(10),  # 데이터 증강: 회전\n",
        "    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),  # 데이터 증강: 기하학적 변환\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Load"
      ],
      "metadata": {
        "id": "AOg-XdYBJsO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 훈련 데이터: 데이터 증강 적용\n",
        "- 테스트 데이터: 증강 없이 원본 이미지 정규화만 수행\n",
        "- DataLoader 사용해 데이터 배치 처리 및 샘플링 수행\n",
        "  - 훈련과 테스트 데이터를 미니배치 단위로 나눠 처리\n",
        "  - batch_size= 한번에 64개 이미지 가져와서 학습\n",
        "  - shuffle=true: 데이터 순서 랜덤하게 섞어 데이터 순서에 의존하지 않도록 과적합 방지\n",
        "  - 매 Epoch마다 랜덤하게 섞어 일반화 성능 향상\n",
        "- 테스트셋\n",
        "  - 모델 평가 시 연산 속도 최적화하기 위해 큰 배치 크기 사용\n",
        "  - 모델 평가에서는 가중치 업데이트가 없어 큰 배치 사용 가능\n",
        "  - 테스트 데이터는 항상 같은 순서로 평가해야 평가 결과 일관됨"
      ],
      "metadata": {
        "id": "za1X-dIPKOWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform_train, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform_test, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
      ],
      "metadata": {
        "id": "gWY3m3XqI__A"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Residual Block"
      ],
      "metadata": {
        "id": "c4Wmqh36-C6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- in_channels: 입력 채널 개수\n",
        "- out_channels: 출력 채널 개수\n",
        "- stride: 합성곱 연산에서 사용하는 보폭(기본값 = 1)\n",
        "- downsample: 입력과 출력의 크기가 다를 경우 1x1 컨볼루션 적용해 차원을 맞춤"
      ],
      "metadata": {
        "id": "in-68UqEP38b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Residual Block 동작방식"
      ],
      "metadata": {
        "id": "PwqhVCtTRTv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 입력(x)을 그대로 유지하는 residual 생성\n",
        "2. 두개의 3x3 컨볼루션 통과하며 특징 학습\n",
        "3. 입력 그대로 출력과 더해 잔차 연결 적용\n",
        "4. ReLU 활성화 후 최종 출력"
      ],
      "metadata": {
        "id": "2rG3miTARZVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- self.conv1, bn1: 첫번째 합성곱 연산은 3x3 커널을 사용하여 특징 추출, padding=1을 설정해 입력 크기 유지, BatchNorm이 편향 조정해 bias 불필요\n",
        "- self.conv2, bn2: 두번째 합성곱 연산도 커널 3x3 사용하고 stride =1로 크기 유지하면서 특징 추출, Bachnorm 적용\n",
        "- 입력 출력의 크기가 다를 경우 다운샘플링 사용해 크기 맞춤\n",
        "- 순전파는 입력 데이터 residual에 저장해 out과 나중에 더함\n",
        "- 첫번째 합성곱 거쳐 첫번째 특징 맵 생성 후 BatchNorm 적용 > ReLU로 활성화해 비선형성 추가\n",
        "- 두번재는 ReLU 적용 안하고 다음 잔차 연결에서 적용\n",
        "- ReLU 마지막으로 한번 더 적용해 비선형성 추가"
      ],
      "metadata": {
        "id": "RSjs7jc2QKOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += residual  # 잔차 연결 (Residual Connection)\n",
        "        out = self.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "293KVFsqM2U5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet 모델 구현"
      ],
      "metadata": {
        "id": "HguwoeEzM-kC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- conv1: 입력 채널은 1, 출력 채널은 64(흑백이기 때문)\n",
        "- 첫번째 합성곱층에서는 16~64개 정도 필터 사용\n",
        "- conv2: stride=2를 적용해 공간적 차원 축소(높이, 너비) -> 추상적 특징 학습\n",
        "- avg_pool: Adaptive Average Pooling 사용해 입력 크기에 상관없이 마지막 특징 맵 1x1 크기로 축소 -> 클래스 분류 문제에 맞춰 최종 출력 생성\n",
        "- fc: Flatten 된 특징을 받아 최종적으로 클래스 개수로 매핑하는 완전 연결 레이어\n",
        "- make_layer로 Residual Block들을 하나의 계층으로 묶어줌\n"
      ],
      "metadata": {
        "id": "8W6qSWoaRmG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 순전파와 역전파 개념"
      ],
      "metadata": {
        "id": "I39w1hrQTttF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\t-\t순전파(Forward Propagation): 입력 데이터를 받아 신경망을 거쳐 최종 출력을 계산하는 과정\n",
        "\t-\t역전파(Backward Propagation): 모델이 예측한 값과 실제 값의 차이(손실, Loss)를 이용하여 가중치를 업데이트하는 과정\n",
        "\n",
        "  순전파 과정\n",
        "  1.\t입력 데이터(x)가 신경망을 통과하며 변환됨\n",
        "  2.\t합성곱 레이어(Conv2D), 활성화 함수(ReLU), BatchNorm, 풀링(Pooling) 등의 연산을 거침\n",
        "  3.\t완전 연결 레이어(FC)를 거쳐 최종 예측 값(output)을 생성\n",
        "  4.\t출력 값(output)이 손실 함수(Loss Function)로 전달됨\n",
        "\n",
        "  역전파 과정\n",
        "  1.\t손실 함수(Loss Function): 예측 값과 실제 값의 차이를 계산\n",
        "\t2.\t기울기(Gradient) 계산: 각 가중치(Weight)에 대한 손실의 기울기를 자동으로 계산 (loss.backward())\n",
        "\t3.\t가중치 업데이트: 옵티마이저(Optimizer)를 사용하여 가중치를 업데이트 (optimizer.step())"
      ],
      "metadata": {
        "id": "y26b9vCITvjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetMNIST(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNetMNIST, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)  # MNIST는 흑백(1채널)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(64, 64, 2)\n",
        "        self.layer2 = self.make_layer(64, 128, 2, stride=2)\n",
        "        self.layer3 = self.make_layer(128, 256, 2, stride=2)\n",
        "        self.layer4 = self.make_layer(256, 512, 2, stride=2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def make_layer(self, in_channels, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(in_channels, out_channels, stride, downsample))\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(ResidualBlock(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avg_pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "DDGjzg6BM-70"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 및 평가 함수"
      ],
      "metadata": {
        "id": "YKhi9v7pNElt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f\"Epoch {epoch} [{batch_idx}/{len(train_loader)}] Loss: {loss.item():.4f}\")\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "IHVzI5zvNGvo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 최적 모델 선택 및 학습"
      ],
      "metadata": {
        "id": "g56zZJJTNIxT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- CrossEntropyLoss는 다중 클래스 분류 문제에서 사용하는 손실 함수\n",
        "- 소프트맥스 확률값과 실제 정답을 비교하여 손실을 계산함\n",
        "예측값과 실제값을 비교해 손실을 줄이는 방향으로 가중치 업데이트"
      ],
      "metadata": {
        "id": "ID2Ym27uU3hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ResNetMNIST().to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "NcKuanERNK2a"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 진행"
      ],
      "metadata": {
        "id": "KFMI_i7NNMus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 10):  # 10 Epoch 학습\n",
        "    train(model, device, train_loader, optimizer, criterion, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKoyVdZ-NN35",
        "outputId": "8c22c2fa-dec4-4acf-b682-cba540c9d9c4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 [0/938] Loss: 2.5245\n",
            "Epoch 1 [100/938] Loss: 0.1690\n",
            "Epoch 1 [200/938] Loss: 0.1130\n",
            "Epoch 1 [300/938] Loss: 0.1122\n",
            "Epoch 1 [400/938] Loss: 0.1400\n",
            "Epoch 1 [500/938] Loss: 0.0725\n",
            "Epoch 1 [600/938] Loss: 0.0727\n",
            "Epoch 1 [700/938] Loss: 0.0919\n",
            "Epoch 1 [800/938] Loss: 0.1318\n",
            "Epoch 1 [900/938] Loss: 0.1047\n",
            "Test Accuracy: 98.58%\n",
            "Epoch 2 [0/938] Loss: 0.0277\n",
            "Epoch 2 [100/938] Loss: 0.0463\n",
            "Epoch 2 [200/938] Loss: 0.0566\n",
            "Epoch 2 [300/938] Loss: 0.0477\n",
            "Epoch 2 [400/938] Loss: 0.0456\n",
            "Epoch 2 [500/938] Loss: 0.2124\n",
            "Epoch 2 [600/938] Loss: 0.0233\n",
            "Epoch 2 [700/938] Loss: 0.0183\n",
            "Epoch 2 [800/938] Loss: 0.1493\n",
            "Epoch 2 [900/938] Loss: 0.1193\n",
            "Test Accuracy: 99.06%\n",
            "Epoch 3 [0/938] Loss: 0.1069\n",
            "Epoch 3 [100/938] Loss: 0.0052\n",
            "Epoch 3 [200/938] Loss: 0.1309\n",
            "Epoch 3 [300/938] Loss: 0.0805\n",
            "Epoch 3 [400/938] Loss: 0.3768\n",
            "Epoch 3 [500/938] Loss: 0.1098\n",
            "Epoch 3 [600/938] Loss: 0.0038\n",
            "Epoch 3 [700/938] Loss: 0.0233\n",
            "Epoch 3 [800/938] Loss: 0.0493\n",
            "Epoch 3 [900/938] Loss: 0.0472\n",
            "Test Accuracy: 98.91%\n",
            "Epoch 4 [0/938] Loss: 0.0050\n",
            "Epoch 4 [100/938] Loss: 0.0321\n",
            "Epoch 4 [200/938] Loss: 0.0256\n",
            "Epoch 4 [300/938] Loss: 0.0157\n",
            "Epoch 4 [400/938] Loss: 0.0579\n",
            "Epoch 4 [500/938] Loss: 0.0903\n",
            "Epoch 4 [600/938] Loss: 0.0350\n",
            "Epoch 4 [700/938] Loss: 0.1673\n",
            "Epoch 4 [800/938] Loss: 0.0963\n",
            "Epoch 4 [900/938] Loss: 0.0376\n",
            "Test Accuracy: 99.21%\n",
            "Epoch 5 [0/938] Loss: 0.0744\n",
            "Epoch 5 [100/938] Loss: 0.1077\n",
            "Epoch 5 [200/938] Loss: 0.0018\n",
            "Epoch 5 [300/938] Loss: 0.0282\n",
            "Epoch 5 [400/938] Loss: 0.0409\n",
            "Epoch 5 [500/938] Loss: 0.0462\n",
            "Epoch 5 [600/938] Loss: 0.0983\n",
            "Epoch 5 [700/938] Loss: 0.0425\n",
            "Epoch 5 [800/938] Loss: 0.1562\n",
            "Epoch 5 [900/938] Loss: 0.0075\n",
            "Test Accuracy: 99.35%\n",
            "Epoch 6 [0/938] Loss: 0.0534\n",
            "Epoch 6 [100/938] Loss: 0.0210\n",
            "Epoch 6 [200/938] Loss: 0.0024\n",
            "Epoch 6 [300/938] Loss: 0.0332\n",
            "Epoch 6 [400/938] Loss: 0.0036\n",
            "Epoch 6 [500/938] Loss: 0.0089\n",
            "Epoch 6 [600/938] Loss: 0.1526\n",
            "Epoch 6 [700/938] Loss: 0.0029\n",
            "Epoch 6 [800/938] Loss: 0.1189\n",
            "Epoch 6 [900/938] Loss: 0.0305\n",
            "Test Accuracy: 99.34%\n",
            "Epoch 7 [0/938] Loss: 0.0346\n",
            "Epoch 7 [100/938] Loss: 0.0077\n",
            "Epoch 7 [200/938] Loss: 0.0285\n",
            "Epoch 7 [300/938] Loss: 0.1102\n",
            "Epoch 7 [400/938] Loss: 0.0091\n",
            "Epoch 7 [500/938] Loss: 0.0072\n",
            "Epoch 7 [600/938] Loss: 0.0360\n",
            "Epoch 7 [700/938] Loss: 0.0315\n",
            "Epoch 7 [800/938] Loss: 0.0471\n",
            "Epoch 7 [900/938] Loss: 0.1088\n",
            "Test Accuracy: 99.17%\n",
            "Epoch 8 [0/938] Loss: 0.0132\n",
            "Epoch 8 [100/938] Loss: 0.0598\n",
            "Epoch 8 [200/938] Loss: 0.0929\n",
            "Epoch 8 [300/938] Loss: 0.0045\n",
            "Epoch 8 [400/938] Loss: 0.0071\n",
            "Epoch 8 [500/938] Loss: 0.1236\n",
            "Epoch 8 [600/938] Loss: 0.0064\n",
            "Epoch 8 [700/938] Loss: 0.0116\n",
            "Epoch 8 [800/938] Loss: 0.0024\n",
            "Epoch 8 [900/938] Loss: 0.0049\n",
            "Test Accuracy: 99.34%\n",
            "Epoch 9 [0/938] Loss: 0.0043\n",
            "Epoch 9 [100/938] Loss: 0.0265\n",
            "Epoch 9 [200/938] Loss: 0.0056\n",
            "Epoch 9 [300/938] Loss: 0.0122\n",
            "Epoch 9 [400/938] Loss: 0.0026\n",
            "Epoch 9 [500/938] Loss: 0.0273\n",
            "Epoch 9 [600/938] Loss: 0.0053\n",
            "Epoch 9 [700/938] Loss: 0.0018\n",
            "Epoch 9 [800/938] Loss: 0.0076\n",
            "Epoch 9 [900/938] Loss: 0.0067\n",
            "Test Accuracy: 99.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습이 완료된 모델 저장\n",
        "model_save_path = \"./mnist_resnet.pth\"\n",
        "torch.save(model.state_dict(), model_save_path)"
      ],
      "metadata": {
        "id": "miyt5U5fOLsH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 손실 2.52 -> 0.006까지 감소\n",
        "- Test Accuracy 99.49%"
      ],
      "metadata": {
        "id": "EjLkSW-xVVEA"
      }
    }
  ]
}